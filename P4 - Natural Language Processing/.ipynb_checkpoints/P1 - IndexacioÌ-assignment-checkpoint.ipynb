{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4526a9e9",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9f5bf",
   "metadata": {},
   "source": [
    "El Natural Language Processing o NLP és el tractament de dades textuals escrites en alguna llengua concreta. En aquesta pràctica veurem dues de les seves aplicacions: la recuperació d'informació i la classificació amb Naive Bayes.\n",
    "\n",
    "<b>Dades del Projecte Gutenberg</b>. Les dades amb les quals treballarem primer són textos de l'escriptor anglès del segle XIX Henry Rider Haggard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344cdbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "from os.path import basename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2c32d0",
   "metadata": {},
   "source": [
    "## Abans de començar\n",
    "\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i paràmetres ja donats**\n",
    "\n",
    "\n",
    "**\\+ En les funcions, s'especifica què serà i de quin tipus cada un dels paràmetres, cal respectar-ho**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739bb8df",
   "metadata": {},
   "source": [
    "## 1. Recuperació d'informació"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fea75",
   "metadata": {},
   "source": [
    "\n",
    "La recuperació d'informació es preocupa pel problema que apareix quan un usuari vol cercar un document textual en una base de dades. En aquesta pràctica us donem una col·lecció de textos literaris del Projecte Gutenberg (https://www.gutenberg.org/). Com trobaríeu un llibre que contingui les paraules \"eye\", \"father\", \"work\"? Penseu en el cercador de Google: quan feu una cerca, el sistema ha de:\n",
    "\n",
    "1. Trobar documents que contenen les vostres paraules clau,\n",
    "\n",
    "2. Mostrar-vos els resultats de la cerca amb un ordre de major a menor rellevància.\n",
    "\n",
    "Sobre aquest esquema bàsic es poden fer moltes millores, com ara la cerca aproximada de text o la personalització de resultats. A més, hi pot haver moltes maneres d'ordenar els resultats. Aquí veurem una versió relativament simple del procés, i en particular només cercarem de manera exacta. Veient el següent esquema del procés de recuperació d'informació:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f008c97",
   "metadata": {},
   "source": [
    "<img width=\"60%\" src=\"img/esquema-recuperacio-informacio.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a66ed",
   "metadata": {},
   "source": [
    "nosaltres farem les parts d'indexació, query, i sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f5523",
   "metadata": {},
   "source": [
    "### Indexació\n",
    "\n",
    "La indexació consisteix en incorporar documents al nostre sistema de manera que ens resulti senzill trobar-los posteriorment. Per efectuar tal tasca, emprarem una estructura de dades anomenada **Índex Invers**. Per entendre com es fabrica, considerem una taula de documents amb algunes de les paraules que contenen: cada columna representa un document, i cada fila ens indica si aquell document conté la corresponent paraula.\n",
    "\n",
    "|          | Document 1 | Document 2 | Document 3 | Document 4 |\n",
    "|:--------:|:----------:|:----------:|:----------:|:----------:|\n",
    "| Einstein |  1         |  1         |  0         |  0         |\n",
    "|  Hubble  |  1         |  1         |  1         |  0         |\n",
    "|   Fermi  |  1         |  0         |  0         |  0         |\n",
    "|  Winfrey |  0         |  0         |  0         |  1         |\n",
    "|   Dylan  |  0         |  0         |  1         |  1         |\n",
    "\n",
    "Quins documents parlen de Hubble? Llegint la segona fila està molt clar: els tres primers. L'essència de l'índex invers es basa en cercar els termes que volem al llistat de paraules indexades, i retornar la seva \"fila\", és a dir, els documents que la contenen.\n",
    "\n",
    "A la pràctica, no podem guardar el nostre índex en una taula: tindríem un problema d'espai. A banda, necessitem una manera ràpida de cercar a la llista de paraules indexades. La cerca ràpida s'aconsegueix amb una estructura de tipus hash. Si volem una estructura de tipus hash que pugui guardar informació associada a cada terme, necessitem usar **diccionaris**. A cada terme li assignarem un conjunt (`set`) de strings, cadascuna amb l'identificador del document que pertoqui. D'aquesta manera, la taula anterior quedaria convertida en el següent diccionari:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Einstein\": {\"Document 1\", \"Document 2\"},\n",
    "    \"Hubble\": {\"Document 1\", \"Document 2\", \"Document 3\"},\n",
    "    \"Fermi\": {\"Document 1\"},\n",
    "    \"Winfrey\": {\"Document 4\"},\n",
    "    \"Dylan\": {\"Document 3\", \"Document 4\"}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd048dc5",
   "metadata": {},
   "source": [
    "Per crear el vostre index invers, us proporcionem la funció `tokenize` i la classe `IndexInvers`. La funció `tokenize` és un generador que agafa un text i va treient cadascuna de les paraules que conté, de manera que podeu iterar sense haver de pensar com separar els espais i la puntuació. \n",
    "\n",
    "La classe `IndexInvers` només conté el constructor, en el qual es creen els seus atributs:\n",
    "- `tdf` (Term-document frequency): el diccionari que acabem de descriure. És del tipus `defaultdict(set)`. Això vol dir que podem accedir (i tractar amb) qualsevol clau. Si per exemple tenim la paraula \"Avui\" i la clau `tdf[\"Avui\"]` no existeix, en comptes de llençar una excepció, el `defaultdict` ens crearà la clau i aquesta contidrà un conjunt buit. \n",
    "- `doc_ids` (identificadors de document): llista on guardarem els identificadors dels documents que indexem. Serà necessari al moment de cercar a l'índex.\n",
    "\n",
    "Els identificadors consistiran en les rutes als arxius de text indexats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5ba79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def tokenize(text, lowercase=True):\n",
    "    text = text.lower() if lowercase else text\n",
    "    for match in re.finditer(r\"\\w+(\\.?\\w+)*\", text):\n",
    "        yield match.group()\n",
    "\n",
    "        \n",
    "class IndexInvers:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tdf = defaultdict(set)\n",
    "        self.doc_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd9735f",
   "metadata": {},
   "source": [
    "**Exercici 1.** \n",
    "\n",
    "Implementeu la funció `index_document`, que a partir d'un índex invers, un identificador de document i un iterable de paraules, afegeixi el document a l'índex invers segons s'ha descrit al text introductori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07b1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_document(inverse_index, doc_id, words):\n",
    "    \"\"\"Afegeix el document referenciat per doc_id i l'indexa d'acord amb les seves paraules. \n",
    "    Aquesta funció no ha de retornar res, només modificar els atributs de l'índex invers\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus IndexInvers\n",
    "        doc_id: string identificativa del document\n",
    "        words: objecte iterable de les paraules del document\n",
    "    \"\"\"        \n",
    "    # Iterate over all the words    \n",
    "    for word in words:\n",
    "        # Add the document ID to each word\n",
    "        inverse_index.tdf[word].add(doc_id)\n",
    "    # Add also on the docs_ids\n",
    "    inverse_index.doc_ids.append(doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ac457",
   "metadata": {},
   "source": [
    "La funció `create_index` utilitza l'`index_document` que heu implementat per crear un índex invers amb els documents indicats. Executeu la següent cel·la per indexar els textos de la carpeta `haggard`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3328837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(filenames):\n",
    "    \"\"\"Crea i retorna un índex invers amb els documents d'una llista indexats.\n",
    "        \n",
    "    Input:\n",
    "        filenames: llista de documents a indexar\n",
    "        \n",
    "    Returns:\n",
    "        Un objecte de tipus IndexInvers\n",
    "    \"\"\"\n",
    "    inverse_index = IndexInvers()\n",
    "    \n",
    "    for filename in filenames:\n",
    "        index_document(inverse_index, \n",
    "                       basename(filename), \n",
    "                       tokenize(open(filename, encoding=\"utf-8\").read()))    \n",
    "    return inverse_index\n",
    "\n",
    "inverse_index = create_index(glob('data/haggard/*.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb2294",
   "metadata": {},
   "source": [
    "Els següents tests haurien de donar `True` si heu implementat l'indexació correctament:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b991a04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('The Ghost Kings 8184.txt' in inverse_index.tdf['master'])\n",
    "print('Cleopatra 2769.txt' in inverse_index.tdf['children'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db727909",
   "metadata": {},
   "source": [
    "**Exercici 2.**\n",
    "\n",
    "Amb l'índex creat, ja podem fer cerques! Implementeu la funció `query` de manera que, donada una paraula clau, ens retorni tots els documents que la contenen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d83bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_one(inverse_index, term):\n",
    "    \"\"\"Troba tots els documents de l'índex que coincideixin amb el terme cercat.\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus InverseIndex\n",
    "        term: paraula \n",
    "        \n",
    "    Returns:\n",
    "        conjunt amb els documents que contenen la paraula\n",
    "    \"\"\"\n",
    "    return inverse_index.tdf[term]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd095120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Allan and the Ice Gods (1927) 0200201.txt', 'Cetywayo and his White Neighbours Remarks on Recent Events in Zululand, Natal, and the Transvaal 8667.txt', 'Mr. Meesons Will 11913.txt', 'Smith and the Pharaohs, and other Tales 6073.txt', 'A Yellow God an Idol of Africa 2857.txt', 'Moon of Israel 2856.txt', 'The People of the Mist 6769.txt', 'The Brethren 2762.txt', 'Lysbeth, a Tale of the Dutch 5754.txt', 'The Worlds Desire 2763.txt', 'Morning Star 2722.txt', 'Ayesha, the Return of She 5228.txt', 'King Solomons Mines 2166.txt', 'The Ghost Kings 8184.txt', 'Stories by English Authors Africa (Selected by Scribners) 1980.txt', 'Montezumas Daughter 1848.txt', 'Marie An Episode in The Life of the late Allan Quatermain 1690.txt', 'Elissa 2855.txt', 'The Wizard 2893.txt', 'Allan and the Holy Flower 5174.txt', 'She and Allan 5745.txt', 'Maiwas Revenge 2713.txt', 'Allans Wife 2727.txt', 'The Tale of Three Lions 2729.txt', 'Eric Brighteyes 2721.txt', 'Wisdoms Daughter (1923) 0200181.txt', 'Finished 1724.txt', 'Dawn 10892.txt', 'Heu-Heu (1924) 0200191.txt', 'Pearl-Maiden 5175.txt', 'The Mahatma and the Hare 2764.txt', 'She 3155.txt', 'Swallow a tale of the great trek 4074.txt', 'Love Eternal 3709.txt', 'Regeneration 13434.txt', 'Cleopatra 2769.txt', 'Colonel Quaritch, V.C. A Tale of Country Life 11882.txt', 'Red Eve 3094.txt', 'Black Heart and White Heart 2842.txt', 'Queen Shebas Ring 2602.txt', 'Stella Fregelius 6051.txt', 'The Wanderers Necklace 3097.txt', 'The Virgin of the Sun 3153.txt', 'The Witchs Head (1884) 0500791.txt', 'Child of Storm 1711.txt', 'Fair Margaret 9780.txt', 'A Winter Pilgrimage (1901) 0600121.txt', 'Long Odds 1918.txt', 'Nada the Lily 1207.txt', 'The Ivory Child 2841.txt', 'The Ancient Allan 5746.txt', 'Benita, an African romance 2761.txt', 'Jess 5898.txt', 'Allan Quatermain 711.txt', 'The Lady of Blossholme 3813.txt', 'Beatrice 3096.txt', 'Queen of the Dawn (1925) 0200381.txt', 'Doctor Therne 5764.txt', 'When the World Shook; being an account of the great adventure of Bastin, Bickley and Arbuthnot 1368.txt'}\n",
      "{'Allan and the Ice Gods (1927) 0200201.txt', 'Cetywayo and his White Neighbours Remarks on Recent Events in Zululand, Natal, and the Transvaal 8667.txt', 'Mr. Meesons Will 11913.txt', 'Smith and the Pharaohs, and other Tales 6073.txt', 'A Yellow God an Idol of Africa 2857.txt', 'Moon of Israel 2856.txt', 'The People of the Mist 6769.txt', 'The Brethren 2762.txt', 'Lysbeth, a Tale of the Dutch 5754.txt', 'The Worlds Desire 2763.txt', 'Morning Star 2722.txt', 'Ayesha, the Return of She 5228.txt', 'King Solomons Mines 2166.txt', 'The Ghost Kings 8184.txt', 'Stories by English Authors Africa (Selected by Scribners) 1980.txt', 'Montezumas Daughter 1848.txt', 'Marie An Episode in The Life of the late Allan Quatermain 1690.txt', 'Elissa 2855.txt', 'The Wizard 2893.txt', 'Allan and the Holy Flower 5174.txt', 'She and Allan 5745.txt', 'Maiwas Revenge 2713.txt', 'Allans Wife 2727.txt', 'The Tale of Three Lions 2729.txt', 'Eric Brighteyes 2721.txt', 'Wisdoms Daughter (1923) 0200181.txt', 'Finished 1724.txt', 'Dawn 10892.txt', 'Heu-Heu (1924) 0200191.txt', 'Pearl-Maiden 5175.txt', 'The Mahatma and the Hare 2764.txt', 'She 3155.txt', 'Swallow a tale of the great trek 4074.txt', 'Love Eternal 3709.txt', 'Hunter Quatermains Story 2728.txt', 'Regeneration 13434.txt', 'Cleopatra 2769.txt', 'Colonel Quaritch, V.C. A Tale of Country Life 11882.txt', 'Red Eve 3094.txt', 'Black Heart and White Heart 2842.txt', 'Queen Shebas Ring 2602.txt', 'Stella Fregelius 6051.txt', 'The Wanderers Necklace 3097.txt', 'The Virgin of the Sun 3153.txt', 'The Witchs Head (1884) 0500791.txt', 'Child of Storm 1711.txt', 'Fair Margaret 9780.txt', 'A Winter Pilgrimage (1901) 0600121.txt', 'Nada the Lily 1207.txt', 'The Ivory Child 2841.txt', 'The Ancient Allan 5746.txt', 'Benita, an African romance 2761.txt', 'Jess 5898.txt', 'Allan Quatermain 711.txt', 'The Lady of Blossholme 3813.txt', 'Beatrice 3096.txt', 'Queen of the Dawn (1925) 0200381.txt', 'Doctor Therne 5764.txt', 'When the World Shook; being an account of the great adventure of Bastin, Bickley and Arbuthnot 1368.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(query_one(inverse_index, \"children\"))\n",
    "print(query_one(inverse_index, \"father\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5740d5b",
   "metadata": {},
   "source": [
    "La possibilitat de fer cerques ens és útil en el moment en què podem entrar més d'un terme simultàniament. Si cerquem el text \"fa bon dia\", volem trobar els documents que continguin aquestes tres paraules (no necessàriament en aquest ordre). Dit d'una altra manera, volem la intersecció de les cerques dels termes \"fa\", \"bon\" i \"dia\".\n",
    "\n",
    "**Exercici 3.**\n",
    "\n",
    "Implementeu la funció `query_terms` de manera que donada una llista de paraules clau `*terms` ens retorni tots els documents que continguin totes les paraules clau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8efdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_terms(inverse_index, terms):\n",
    "    \"\"\"Troba tots els documents de l'índex que coincideixin amb els termes de la cerca.\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus InverseIndex\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        conjunt amb els documents que coincideixen amb la cerca.\n",
    "    \"\"\"\n",
    "    # Get the first term because we are gonna use the intersection function\n",
    "    # This function will only get when the docs_id are the same\n",
    "    result = inverse_index.tdf[terms[0]]\n",
    "    for term in terms[1:]:\n",
    "        result = result.intersection(inverse_index.tdf[term])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a94aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The Ivory Child 2841.txt', 'Allan Quatermain 711.txt', 'Finished 1724.txt', 'Ayesha, the Return of She 5228.txt', 'When the World Shook; being an account of the great adventure of Bastin, Bickley and Arbuthnot 1368.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(query_terms(inverse_index, [\"eye\", \"father\", \"work\", \"today\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffcecc",
   "metadata": {},
   "source": [
    "**Exercici 4.**\n",
    "\n",
    "Podem voler també cercar documents que continguin *alguna* de les paraules clau. Implementeu la funció `query_some_terms` per aconseguir aquest comportament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0a11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_some_terms(inverse_index, terms):\n",
    "    \"\"\"Troba tots els documents de l'índex que coincideixin amb algun dels termes de la cerca.\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus InverseIndexCounter\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        conjunt amb els documents que contenen alguna de les paraules\n",
    "    \"\"\"\n",
    "    res = set()\n",
    "    # For this function we will use union because we want any of the terms\n",
    "    for term in terms:        \n",
    "        res = res.union(inverse_index.tdf[term])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16a612",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Amb la funció `query_terms`, ja podem cercar qualsevol document a la nostra base de dades. Però amb això no n'hi ha prou: què passarà quan la cerca retorni massa resultats? Necessitem una manera d'ordenar els documents que apareguin a la cerca, preferiblement de més a menys rellevància.\n",
    "\n",
    "Per fer-ho, necessitem una versió modificada del nostre índex invers. Per començar, necessitem guardar la longitud de cada document. Com que cada document té un identificador, això ho podem fer directament amb un diccionari. També ho podem fer amb una estructura una mica diferent, anomenada `Counter` (https://docs.python.org/3/library/collections.html#collections.Counter).\n",
    "\n",
    "Tal com diu la documentació de `collections`, un Counter és un diccionari que ens permet comptar. Cadascun dels seus valors és només un `int`, i podem incrementar-lo sense haver de definir cada clau. Té molta similitud amb un `defaultdict(int)`. Veiem-ho amb un exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91659ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gos': 3, 'gat': 2, 'gallina': 1, 'serp': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "animals = [\"gos\", \"gat\", \"gos\", \"gos\", \"gallina\", \"serp\", \"gat\"]\n",
    "for a in animals:\n",
    "    counter[a] += 1\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed66c9ba",
   "metadata": {},
   "source": [
    "L'avantatge de counter és que no cal fer el bucle for! El següent codi fa exactament el mateix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf35145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gos': 3, 'gat': 2, 'gallina': 1, 'serp': 1})\n"
     ]
    }
   ],
   "source": [
    "counter2 = Counter(animals)\n",
    "print(counter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac7ccd",
   "metadata": {},
   "source": [
    "També disposem del mètode `most_common`, que ens dóna els n termes més comuns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c66cdde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gos', 3), ('gat', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(counter2.most_common(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8f46e",
   "metadata": {},
   "source": [
    "La utilitat del `Counter` pot no estar massa clara per comptar la longitud de cada text. Hi ha una altra aplicació per la qual ens serà molt útil. Per poder ordenar els resultats de la nostra cerca, voldrem saber quantes vegades surt una paraula a cada text. Això ho podem aconseguir canviant el `tdf` del nostre índex invers (que era un `defaultdict(set)`) per un `defaultdict(Counter)`. \n",
    "\n",
    "D'aquesta manera no només sabrem quins documents contenen cada paraula, sino també la seva freqüència. Això justifica el nom TDF (Term-Document Frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f88af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexInversCounter:\n",
    "    \"\"\"El mateix que IndexInvers, però utilitzant defaultict(Counter)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tdf = defaultdict(Counter)\n",
    "        self.lengths = Counter()\n",
    "        self.doc_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a9e3f9",
   "metadata": {},
   "source": [
    "**Exercici 5.**\n",
    "\n",
    "Implementeu la funció `index_document_counter`, que a partir d'un índex invers `IndexInversCounter`, un identificador de document i un iterable de paraules, afegeixi el document a l'índex invers segons s'ha descrit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5249ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_document_counter(inverse_index, doc_id, words):\n",
    "    \"\"\"Afegeix el document referenciat per doc_id i l'indexa d'acord amb les seves paraules. \n",
    "    Aquesta funció no ha de retornar res, només modificar els atributs de l'índex invers\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus IndexInversCounter\n",
    "        doc_id: string identificativa del document\n",
    "        words: objecte iterable de les paraules del document\n",
    "    \"\"\"\n",
    "    # Create a counter from all the words\n",
    "    counted_words = Counter(words)        \n",
    "    # Iterate over all the words\n",
    "    for word in counted_words:\n",
    "        # For each word and each document, save the number of occurrence of that word\n",
    "        inverse_index.tdf[word][doc_id] = counted_words[word]\n",
    "    \n",
    "    # Finally sum all the values from counter to have the length of the document\n",
    "    inverse_index.lengths[doc_id] = sum(counted_words.values()) \n",
    "    \n",
    "    # Also, append the document into the doc_ids\n",
    "    inverse_index.doc_ids.append(doc_id)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76db90a",
   "metadata": {},
   "source": [
    "Executeu la següent cel·la per indexar els textos de la carpeta `haggard`, aquest cop amb comptatge de les longituds de cada text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a12698ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_counter_index(filenames):\n",
    "    \"\"\"Retorna un índex invers amb la llista d'arxius indexats.\n",
    "    \n",
    "    Input:\n",
    "        filenames: llista d'arxius\n",
    "        \n",
    "    Returns:\n",
    "        objecte del tipus IndexInversCounter\n",
    "\n",
    "    \"\"\"\n",
    "    inverse_index = IndexInversCounter()\n",
    "\n",
    "    for filename in filenames:\n",
    "        index_document_counter(inverse_index, basename(filename), tokenize(open(filename, encoding=\"utf-8\").read()))\n",
    "    \n",
    "    return inverse_index\n",
    "\n",
    "inverse_index_counter = create_counter_index(glob('data/haggard/*.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ad542",
   "metadata": {},
   "source": [
    "**Exercici 6.**\n",
    "\n",
    "Ara la cerca no funcionarà, ja que estem treballant amb `Counter`s en comptes de `set`s. Modifiqueu la funció `query_terms` perquè funcioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4815d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_terms_counter(inverse_index, terms):\n",
    "    \"\"\"Troba tots els documents de l'índex que coincideixin amb els termes de la cerca.\n",
    "    \n",
    "    Input:\n",
    "        inverse_index: objecte de tipus InverseIndexCounter\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        conjunt amb els documents que coincideixen amb la cerca.\n",
    "    \"\"\"            \n",
    "    # Get always the first term\n",
    "    result = set(inverse_index.tdf[terms[0]])    \n",
    "    # Intersect with the rest of terms\n",
    "    for term in terms[1:]:\n",
    "        result = result.intersection(set(inverse_index.tdf[term]))\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05687c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Allan and the Ice Gods (1927) 0200201.txt', 'Cetywayo and his White Neighbours Remarks on Recent Events in Zululand, Natal, and the Transvaal 8667.txt', 'Mr. Meesons Will 11913.txt', 'Smith and the Pharaohs, and other Tales 6073.txt', 'A Yellow God an Idol of Africa 2857.txt', 'Moon of Israel 2856.txt', 'The People of the Mist 6769.txt', 'The Brethren 2762.txt', 'Lysbeth, a Tale of the Dutch 5754.txt', 'The Worlds Desire 2763.txt', 'Morning Star 2722.txt', 'Ayesha, the Return of She 5228.txt', 'King Solomons Mines 2166.txt', 'The Ghost Kings 8184.txt', 'Stories by English Authors Africa (Selected by Scribners) 1980.txt', 'Montezumas Daughter 1848.txt', 'Marie An Episode in The Life of the late Allan Quatermain 1690.txt', 'Elissa 2855.txt', 'The Wizard 2893.txt', 'Allan and the Holy Flower 5174.txt', 'She and Allan 5745.txt', 'Maiwas Revenge 2713.txt', 'Allans Wife 2727.txt', 'The Tale of Three Lions 2729.txt', 'Eric Brighteyes 2721.txt', 'Wisdoms Daughter (1923) 0200181.txt', 'Finished 1724.txt', 'Dawn 10892.txt', 'Heu-Heu (1924) 0200191.txt', 'Pearl-Maiden 5175.txt', 'The Mahatma and the Hare 2764.txt', 'She 3155.txt', 'Swallow a tale of the great trek 4074.txt', 'Love Eternal 3709.txt', 'Hunter Quatermains Story 2728.txt', 'Regeneration 13434.txt', 'Cleopatra 2769.txt', 'Colonel Quaritch, V.C. A Tale of Country Life 11882.txt', 'Red Eve 3094.txt', 'Queen Shebas Ring 2602.txt', 'Stella Fregelius 6051.txt', 'The Wanderers Necklace 3097.txt', 'The Virgin of the Sun 3153.txt', 'The Witchs Head (1884) 0500791.txt', 'Child of Storm 1711.txt', 'Fair Margaret 9780.txt', 'A Winter Pilgrimage (1901) 0600121.txt', 'Nada the Lily 1207.txt', 'The Ivory Child 2841.txt', 'The Ancient Allan 5746.txt', 'Benita, an African romance 2761.txt', 'Jess 5898.txt', 'Allan Quatermain 711.txt', 'The Lady of Blossholme 3813.txt', 'Beatrice 3096.txt', 'Queen of the Dawn (1925) 0200381.txt', 'Doctor Therne 5764.txt', 'When the World Shook; being an account of the great adventure of Bastin, Bickley and Arbuthnot 1368.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(query_terms_counter(inverse_index_counter, [\"eye\", \"father\", \"work\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11251f10",
   "metadata": {},
   "source": [
    "Com hem esmentat, hem introduit la modificació amb `Counter` per poder tractar el problema del scoring. Hi ha diverses maneres d'ordenar els resultats de la cerca al nostre índex invers, ara en veurem dues. Quina és la manera més senzilla que se'ns ocorre per ordenar resultats?\n",
    "\n",
    "Podem ordenar els documents segons en quin d'ells apareixen més vegades les paraules que hem cercat. És a dir, si cerquem \"avui\" i en un document hi surt la paraula 10 vegades, li donarem més pes (més puntuació) que a un document on hi surti 5 vegades. D'aquesta manera, la puntuació del document $D$ al cercar els termes $q_1,\\dots,q_n$ serà\n",
    "$$\n",
    "    \\mathrm{score}_D(q_1,\\dots,d_n) = \\sum_{i=1,\\dots,n} freq(q_i,D).\n",
    "$$\n",
    "Aquesta manera de puntuar l'anomenarem \"naive\". \n",
    "\n",
    "**Exercici 7.**\n",
    "\n",
    "Implementeu la funció de puntuació naive per un document donat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4622dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_naive(inverse_index, doc_id, terms):\n",
    "    \"\"\"Puntuació naive d'un document per una cerca concreta\n",
    "    \n",
    "    Inputs:\n",
    "        inverse_index: objecte de tipus IndexInversCounter\n",
    "        doc_id: identificador del document a puntuar\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        un nombre amb la puntuació naive del document, segons la fórmula naive\n",
    "    \"\"\"\n",
    "    # Start with a score as 0\n",
    "    score = 0\n",
    "    # Iterate over all the terms\n",
    "    for term in terms:\n",
    "        # Get the term and the document and sum the occurrence\n",
    "        score += inverse_index.tdf[term][doc_id]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b010d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "print(score_naive(inverse_index_counter, \"The Ghost Kings 8184.txt\", [\"eye\", \"father\", \"work\"]))\n",
    "print(score_naive(inverse_index_counter, \"The Virgin of the Sun 3153.txt\", [\"eye\", \"father\", \"work\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a0919",
   "metadata": {},
   "source": [
    "Ràpidament ens adonem que la manera naive de puntuar pot no ser la millor. Si un document és molt més llarg que la resta, és molt mes probable que la paraula que cerquem hi aparegui freqüentment. Això li donarà una puntuació molt major que a un document més curt que pot ser més rellevant. A banda, cal tenir en compte que certes paraules (com ara els connectors i les preposicions) són massa comuns per donar informació sobre la rellevància d'un resultat de cerca.\n",
    "\n",
    "Una solució a aquests problemes ve donada pel mètode de puntuació Okapi BM25 (https://en.wikipedia.org/wiki/Okapi_BM25). Ve donat per la següent fórmula:\n",
    "\n",
    "$$\\operatorname{score}_D\\left(q_{1}, q_{2}, \\ldots, q_{n}\\right)\n",
    "=\n",
    "\\sum_{i=1}^{n} I D F\\left(q_{i}\\right) \\cdot \n",
    "\\frac{freq\\left(q_{i}, D\\right) \\cdot\\left(k_{1}+1\\right)}\n",
    "{freq\\left(q_{i}, D\\right)+k_{1} \\cdot\\left(1-b+b \\cdot \\frac{|D|}{\\operatorname{avgdl}}\\right)},$$\n",
    "on hi tenim la següent informació:\n",
    "\n",
    "- $freq(q_i, D)$ és la freqüència del terme $q_i$ al document $D$.\n",
    "- $k_1=0.75$ i $b=1.2$ són paràmetres, que es poden ajustar per donar resultats diferents.\n",
    "- $|D|$ és la longitud del document $D$.\n",
    "- $avgdl$ és la longitud mitjana de tots els documents (*av*era*g*e *d*ocument *l*ength)\n",
    "\n",
    "El terme $IDF(q_i)$ es coneix com la Inverse Document Frequency, donat per la fórmula\n",
    "$$I D F\\left(q_{i}\\right)=\\log\\left( 1+ \\frac{N-n\\left(q_{i}\\right)+0.5}{n\\left(q_{i}\\right)+0.5} \\right),$$\n",
    "on $N$ és el nombre de documents indexats, i $n(q_i)$ és el nombre de documents que contenen el terme $q_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa23eb",
   "metadata": {},
   "source": [
    "**Exercici 8.**\n",
    "\n",
    "Implementeu la fórmula de la puntuació Okapi BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "429ee760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "k1 = 0.75\n",
    "b = 1.2\n",
    "\n",
    "def score_okapi(inverse_index, doc_id, terms):\n",
    "    \"\"\"Puntuació Okapi BM25 d'un document per una cerca concreta\n",
    "    \n",
    "    Inputs:\n",
    "        inverse_index: objecte de tipus IndexInversCounter\n",
    "        doc_id: identificador del document a puntuar\n",
    "        terms: llista de paraules\n",
    "        \n",
    "    Returns:\n",
    "        un nombre amb la puntuació Okapi BM25 del document, segons la fórmula descrita.\n",
    "    \"\"\"\n",
    "    # Start with a score as 0\n",
    "    score = 0    \n",
    "    # Iterate over all the terms\n",
    "    for term in terms:\n",
    "        # Get all the values to apply the formula\n",
    "        N = len(inverse_index.doc_ids)\n",
    "        nQ = len(inverse_index.tdf[term])\n",
    "        idf = log(1 + (N - nQ + 0.5) /(nQ + 0.5))\n",
    "        freq = inverse_index.tdf[term][doc_id]        \n",
    "        doc_len = inverse_index.lengths[doc_id]\n",
    "        mean = np.mean(list(inverse_index.lengths.values()))\n",
    "        \n",
    "        # Just apply the formula\n",
    "        score += idf * (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * (doc_len / mean )))        \n",
    "    return score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b242a65b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.09786966124624634\n",
      "0.09755473303338251\n"
     ]
    }
   ],
   "source": [
    "print(score_okapi(inverse_index_counter, \"Hunter Quatermain's Story 2728.txt\", [\"eye\", \"father\", \"work\"]))\n",
    "print(score_okapi(inverse_index_counter, \"The Virgin of the Sun 3153.txt\", [\"eye\", \"father\", \"work\"]))\n",
    "print(score_okapi(inverse_index_counter, \"Nada the Lily 1207.txt\", [\"eye\", \"father\", \"work\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c91b3",
   "metadata": {},
   "source": [
    "**Exercici 9.**\n",
    "\n",
    "Implementeu la cerca de documents amb ordenació per puntuació. La funció `query_n` ha d'admetre un nombre arbitrari de paraules clau, un nombre de resultats màxim esperats, i una funció de puntuació a través del paràmetre `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5082eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_n(inverse_index, terms, n=10, score=score_naive):\n",
    "    \"\"\"Cerca dels n documents amb millor puntuació.\n",
    "    \n",
    "    Inputs:\n",
    "        inverse_index: objecte de tipus IndexInversCounter\n",
    "        terms: llista de paraules\n",
    "        n: número de documents a recuperar\n",
    "        score: funció de puntuació a utilitzar\n",
    "        \n",
    "    Returns:\n",
    "        llista dels n documents amb millor puntuació, ordenats de millor a pitjor.\n",
    "    \"\"\"\n",
    "    # Get all the documents with these terms\n",
    "    query = query_terms_counter(inverse_index, terms)\n",
    "    # Sort the documents by the score\n",
    "    result = sorted(query, key=lambda x: score(inverse_index, x, terms), reverse=True)\n",
    "    # Just return the number of documents that we want\n",
    "    return result[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d19def7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nada the Lily 1207.txt', 'Dawn 10892.txt', 'Stella Fregelius 6051.txt', 'Regeneration 13434.txt', 'Benita, an African romance 2761.txt', 'Lysbeth, a Tale of the Dutch 5754.txt', 'Colonel Quaritch, V.C. A Tale of Country Life 11882.txt', 'Love Eternal 3709.txt', 'Montezumas Daughter 1848.txt', 'Marie An Episode in The Life of the late Allan Quatermain 1690.txt']\n"
     ]
    }
   ],
   "source": [
    "print(query_n(inverse_index_counter, [\"eye\", \"father\", \"work\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47153be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hunter Quatermains Story 2728.txt', 'The Tale of Three Lions 2729.txt', 'The Mahatma and the Hare 2764.txt', 'Maiwas Revenge 2713.txt', 'Allans Wife 2727.txt', 'King Solomons Mines 2166.txt', 'Allan and the Ice Gods (1927) 0200201.txt', 'Allan and the Holy Flower 5174.txt', 'Dawn 10892.txt', 'Lysbeth, a Tale of the Dutch 5754.txt']\n"
     ]
    }
   ],
   "source": [
    "print(query_n(inverse_index_counter, [\"eye\", \"father\", \"work\"], score=score_okapi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b80fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
