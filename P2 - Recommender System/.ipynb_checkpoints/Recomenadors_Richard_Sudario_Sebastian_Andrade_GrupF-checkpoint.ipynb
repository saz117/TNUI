{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemes de Recomanació"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest primer lliurament es programarà un **sistema de recomanació**, que posarà en correspondència un *usuari* amb *ítems* en funció de les seves preferències i interessos. \n",
    "En aquesta ocasió, implementareu un sistema de recomanació que assisteixi en una compra de supermercat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abans de començar\n",
    "\n",
    "\n",
    "**\\+ Durant la pràctica, solament es podran fer servir les següents llibreries**:\n",
    "\n",
    "`Pandas, Numpy, Itertools`\n",
    "\n",
    "*Nota: A més de les que ja es troben presents en la 1a cel·la i funcions natives de Python*\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i paràmetres ja donats**\n",
    "\n",
    "Això no implica però que els hàgiu de fer servir. És a dir, que la funció tingui un paràmetre anomenat `df` no implica que l'hàgiu de fer servir, si no ho trobeu convenient.\n",
    "\n",
    "**\\+ En les funcions, s'especifica que serà i de quin tipus cada un dels paràmetres, cal respectar-ho**\n",
    "\n",
    "Per exemple (ho posarà en el pydoc de la funció), `df` sempre serà indicatiu del `Pandas.DataFrame` de les dades. Durant la correcció, els paràmetres (i específicament `df`) no contindran les mateixes dades que en aquest notebook, si bé si seran del mateix tipus! Per tant, no us refieu de què tinguin, per exemple, el mateix nombre de files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar les dades\n",
    "\n",
    "### **En aquesta cel·la no féu cap modificació**\n",
    "\n",
    "Descomprimeix els zips a la carpeta \"data\" automàticament. \n",
    "\n",
    "Descarregueu el zip amb les dades del campus i guardeu-lo dins de la carpeta del projecte. No pugeu els arxius de dades al campus, només el codi i les prediccions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pickle\n",
    "from os.path import join, dirname\n",
    "\n",
    "def unzip(file):\n",
    "    zip_ref = zipfile.ZipFile(file, 'r')\n",
    "    zip_ref.extractall('data')\n",
    "    zip_ref.close()\n",
    "    \n",
    "unzip('dades_p2.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les dades\n",
    "\n",
    "En aquest notebook farem servir dades reals corresponents a compres, concretament les utilitzades en el Kaggle Instacart Market Basket Analysis:\n",
    "https://www.kaggle.com/c/instacart-market-basket-analysis\n",
    "\n",
    "\n",
    "* **Order Products**: És el de major interès, conté la relació de productes comprats (`product_id`) per a cada conjunt de compra diferent (`order_id`). A aquests conjunts de compres ens hi referirem com a `ordres`, seguint la nomenclatura de les dades. A més, tot i que no ho farem servir, podríem arribar a saber en quin ordre s'han comprat els productes (`add_to_cart_order`) i inclús si ja s'havia comprat en alguna ordre anterior (`reordered`).\n",
    "\n",
    "* **Orders**: Aquest dataset ens permet relacionar una compra en concret (`order_id`) amb l'usuari que l'ha feta (`user_id`)\n",
    "\n",
    "* **Products**: Donat un `product_id` ens permet obtenir-ne més informació, com ara el nom (`product_name`), la secció en la qual es troba (`aisle_id`) o al departament al qual pertany (`department_id`). Aquests dos últims es complementen amb els conjunts **Aisles** i **Departments**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "### **En aquestes cel·les no feu cap modificació**\n",
    "\n",
    "Carrega les dades en un DataFrame Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_order_prods = pd.read_csv(join('data', 'order_products__train.csv'))\n",
    "df_orders = pd.read_csv(join('data', 'orders.csv'))[['order_id', 'user_id']]\n",
    "df_prods = pd.read_csv(join('data', 'products.csv'))[['product_id', 'aisle_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementació\n",
    "\n",
    "Recordeu, seguiu els pydoc i compliu amb el que diuen!\n",
    "\n",
    "El primer que haurem de fer és construir una matriu que ens serveixi, d'alguna forma, com a indicatiu de preferències de cada persona. Per tal efecte, construirem una matriu $m\\times n$, de $m$ usuaris per $n$ items, on cada entrada $i,j$ serà el nombre de vegades que la persona $i$ ha comprat l'item $j$.\n",
    "\n",
    "<img src=\"img/Mat.png\">\n",
    "\n",
    "Per saber de quin usuari és cada `order_id`, haureu de creuar el dataset `order_products` amb el `orders`. Una sola persona/usuari tindrà més d'una ordre, mireu quants cops ha comprat els mateixos productes.\n",
    "\n",
    "A més, les dades es componen de molts `product_id` diferents, hi ha massa diversitat entre usuaris. Per tant, per poder recomanar el que farem serà agregar les dades, en lloc de treballar per `product_id` ho farem per `aisle_id`, és a dir \"la secció\" del súper on es troba.\n",
    "\n",
    "Al llarg de la pràctica es parlarà de producte i/o item, perquè és la terminologia estàndard de recomanadors, però sempre serà en referència a `aisle_id` per aquesta pràctica!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_information(df_order_prods, df_orders, df_prods):\n",
    "    \"\"\"\n",
    "    Retorna el dataframe resultant de:\n",
    "        1. Creuar els datasets 'order_products' amb 'orders'.\n",
    "        2. Creuar el dataframe anterior amb 'products'.\n",
    "        Per creuar dos dataframes podeu utilitzar la funció pandas.DataFrame.merge\n",
    "\n",
    "    :param df_order_prods: DataFrame 'order_products'\n",
    "    :param df_orders: DataFrame 'orders'\n",
    "    :param df_prods: DataFrame 'products'\n",
    "    :return: DataFrame descrit prèviament   \n",
    "    \"\"\"\n",
    "    #Creuar els datasets 'order_products' amb 'orders'\n",
    "    order_products_tmp = pd.DataFrame.merge(df_order_prods, df_orders, how = 'inner', on = 'order_id')\n",
    "    #Creuar el dataframe anterior amb 'products'\n",
    "    df_order_products = pd.DataFrame.merge(order_products_tmp, df_prods, how = 'inner', on = 'product_id')\n",
    "    \"\"\"\n",
    "    we create a temporary data frame with order_products and orders, by merging the two. We use how = 'inner';\n",
    "    Parameter inner means to use intersection of keys from both frames, similar to a SQL inner join; \n",
    "    preserve the order of the left keys. \n",
    "    \n",
    "    We use parameter on = 'order_id' to indicate wich column or index(in this case index) sames we want to join. We\n",
    "    can use order_id because it exists on both DataFrames df_order_prods and df_orders.\n",
    "    \n",
    "    Now that with have the temporary DataFrame, we can create the final merged df (df_order_products), which uses the \n",
    "    same logic as the last one, but with product_id, which also exists in both Dataframes.\n",
    "    \"\"\"\n",
    "    return df_order_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_information(df_order_prods, df_orders, df_prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         order_id  product_id  add_to_cart_order  reordered  user_id  aisle_id\n",
      "0               1       49302                  1          1   112108       120\n",
      "1          816049       49302                  7          1    47901       120\n",
      "2         1242203       49302                  1          1     2993       120\n",
      "3         1383349       49302                 11          1    41425       120\n",
      "4         1787378       49302                  8          0   187205       120\n",
      "...           ...         ...                ...        ...      ...       ...\n",
      "1384612   3420011        1528                 12          0   177077        97\n",
      "1384613   3420084       47935                 20          0     9808        73\n",
      "1384614   3420084        9491                 21          0     9808        25\n",
      "1384615   3420088       16380                 12          0    72444        97\n",
      "1384616   3420895       38900                  9          1    20949         5\n",
      "\n",
      "[1384617 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_counts_table(df):\n",
    "    \"\"\"\n",
    "    Retorna un dataframe on les columnes són els `aisle_id`, les files `user_id` i els valors\n",
    "    el nombre de vegades que un usuari ha comprat un producte d'un `aisle_id`\n",
    "    \n",
    "    :param df: DataFrame original després de creuar-lo\n",
    "    :return: DataFrame descrit adalt\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #We want each aisle_id \"value\" to be a column\n",
    "    \n",
    "    new_df = df.groupby(['user_id', 'aisle_id']).size() #so lets start again and filter the dataFrame by user_id and aisle_id\n",
    "    #now both user_id and aisle_id are indexs, but we dont want aisle_id as an index, we want it as a column\n",
    "    #we also have an extra column with the .size() values, which will give us problems for the get_count() function\n",
    "    \n",
    "    new_df = new_df.reset_index(level = 'aisle_id') #next, we remove aisle_id from the indexes, which gives us a \n",
    "    #dataframe with user_id as index, and aisle_id as a column, but still each value of aisle_id is not a column yet.\n",
    "    #we also still have the extra column with .size() values.\n",
    "    \n",
    "    new_df = new_df.pivot(columns = 'aisle_id')#we make each content of aisle_id a column in the dataframe\n",
    "    new_df.columns = sorted(df.aisle_id.unique()) #we remove the extra column to avoid problems with the get_count() function\n",
    "    #this unfortunately also removes the title aisle_id, because we are re organizing the whole columns, but the values\n",
    "    #remain the same.\n",
    "    new_df = new_df.fillna(0) #we replace all NaNs with zero to avoid problems\n",
    "    \"\"\"\n",
    "    \n",
    "    #we can also just do it like this. it doesnt need to be sorted since the values remain the same, but it looks better\n",
    "    new_df = df.groupby(['user_id','aisle_id'], sort=True).size().unstack(fill_value=0.0) \n",
    "    print(new_df)\n",
    "    return new_df\n",
    "\n",
    "def get_count(df, user_id, aisle_id):\n",
    "    \"\"\"\n",
    "    Retorna el nombre de vegades que un usuari ha comprat en un `aisle_id`\n",
    "    \n",
    "    :param df: DataFrame retornat per `build_counts_table`\n",
    "    :param user_id: ID de l'usuari\n",
    "    :param aisle_id: ID de la secció\n",
    "    :return: Enter amb el nombre de vegades que ha comprat\n",
    "    \"\"\"\n",
    "    #the intersection of the vector is the number of times a user bought something from an aisle\n",
    "    return df.at[user_id, aisle_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aisle_id  1    2    3    4    5    6    7    8    9    10   ...  125  126  \\\n",
      "user_id                                                     ...             \n",
      "1         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2         1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "5         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "7         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "8         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "206199    0.0  0.0  2.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "206200    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "206203    0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "206205    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "206209    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "aisle_id  127  128  129  130  131  132  133  134  \n",
      "user_id                                           \n",
      "1         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "5         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "8         0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "206199    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "206200    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "206203    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "206205    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "206209    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[131209 rows x 134 columns]\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "df_counts = build_counts_table(df_merged)\n",
    "count = get_count(df_counts, 14, 5)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadístiques de les dades\n",
    "\n",
    "Donada la matriu que conté el nombre de vegades que un usuari ha comprat en una secció, calculeu:\n",
    "- Els usuaris que més compren\n",
    "- Les seccions amb més ventes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_active_users(counts, indexes, columns, n):\n",
    "    \"\"\"\n",
    "    Exemple: Retorna els ids dels n usuaris que més compres han fet\n",
    "    \n",
    "    :param counts, indexes, columns: Tupla retornada per `build_counts_table`\n",
    "    :param n: Quanitat d'usuaris\n",
    "    :return: Llista, tupla o pd.Series de userID dels n usuaris\n",
    "    \"\"\"\n",
    "    #we make the sum by columns(aisles) so we can get the total purchases for each column\n",
    "    columns_by_purchase = counts.sum(axis=1)\n",
    "    #print(columns_by_purchase)#we can see the corresponding total purchases made by user\n",
    "    user_by_purchase = columns_by_purchase.argsort() #when we sort the list, it will sort them by user (the indexes\n",
    "    #with more purchases)\n",
    "    #note that these indexes are the ones on columns_by_purchase, which shows the total purchases made by users\n",
    "    return user_by_purchase[0:n].tolist()#we return the top n\n",
    "\n",
    "def top_sales_aisle(counts, indexes, columns, n):\n",
    "    \"\"\"\n",
    "    Exemple: Retorna els ids de les n seccions amb més ventes\n",
    "    \n",
    "    :param counts, indexes, columns: Tupla retornada per `build_counts_table`\n",
    "    :param n: Quanitat de seccions\n",
    "    :return: Llista, tupla o pd.Series de aisle_id de les n seccions\n",
    "    \"\"\"\n",
    "    #we make the sum by indexes(users) so we can get the total purchases by index\n",
    "    index_by_purchase = counts.sum(axis=0)\n",
    "    #print(index_by_purchase)#we can see it shows us the number of purchases on each aisle\n",
    "    aisle_by_purchase = index_by_purchase.argsort()#when we sort the list, it will sort them by aisles (the indexes\n",
    "    #with more purchases)\n",
    "    #again, note that the indexes are the ones on index_by_purchase, which shows the number of purchases on each aisle\n",
    "    return aisle_by_purchase[0:n].tolist() #we return the top n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_users:  [60884, 76156, 47626, 124221, 94767]\n",
      "top_sales:  [131, 112, 81, 101, 9]\n"
     ]
    }
   ],
   "source": [
    "indexes = df_counts.index\n",
    "columns = df_counts.columns\n",
    "\n",
    "top_users = top_active_users(df_counts, indexes, columns, 5)\n",
    "print('top_users: ', top_users)\n",
    "\n",
    "top_sales = top_sales_aisle(df_counts, indexes, columns, 5)\n",
    "print('top_sales: ', top_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenim moltes dades en el nostre dataset, pel que és convenient que les reduïm una mica. Per començar a treballar recomanem que reduïu la mida a aproximadament 0.1 de l'original '(FRAC = 0.1)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC = 0.0045\n",
    "df_reduced = df_counts.sample(frac=FRAC, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesurament de similituds\n",
    "\n",
    "El primer pas per poder recomanar és definir una funció de similitud entre vectors. Siguin $x, y$ vectors, de les següents propostes **implementa totes** i escull una pel teu recomanador:\n",
    "\n",
    "* Distància euclidea (inversa): https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "\n",
    "$$sim(x, y) = \\frac{1}{1 + \\sqrt{\\sum_i(x_i-y_i)^2}}\\in [0, 1]$$\n",
    "\n",
    "* Similitud cosinus: https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "\n",
    "$$sim(x, y) = \\frac{x\\cdot y}{||x||\\hspace{0.1cm} ||y||} \\in [-1,1]$$\n",
    "\n",
    "* Correlació de Pearson: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "\n",
    "$${\\displaystyle sim(x,y)={\\frac {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}{{\\sqrt {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}}}{\\sqrt {\\sum _{i=1}^{n}(y_{i}-{\\bar {y}})^{2}}}}}} \\in [-1,1] \\\\ \\text{On }\\bar{x} = \\frac{1}{n} \\sum^n_i x_i\\text{ la mitja (i anàlogament per y)}$$\n",
    "\n",
    "* Jaccard:  https://en.wikipedia.org/wiki/Jaccard_index\n",
    "\n",
    "$$sim(x,y) = \\frac{|x \\cap y|}{|x \\cup y|}\n",
    "$$\n",
    "\n",
    "Aquesta funció mesura el nombre d'elements en comú dels dos vectors (numerador) i el nombre total d'elements diferents que hi ha entre els dos vectors. Per exemple:\n",
    "\n",
    "$$\n",
    "x = [1, \\text{NaN}, 2, 3, \\text{NaN}, 5] \\\\\n",
    "y = [2, 1, \\text{NaN}, \\text{NaN}, \\text{NaN}, \\text{NaN}] \\\\\n",
    "sim(x, y) = {{|x \\cap y|}\\over{|x \\cup y|}} = {1 \\over{5}} = 0.2\n",
    "$$\n",
    "\n",
    "Per implementar qualsevol d'aquestes únicament es permet l'ús de:\n",
    "\n",
    "* `np.sum`\n",
    "* `np.sqrt`\n",
    "* `np.power`\n",
    "* `np.dot`\n",
    "* `np.linalg.norm`\n",
    "* `np.mean`\n",
    "\n",
    "I s'ha de fer **sense bucles**.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Tingueu en compte que les similituds de Pearson i Cosinus consideren valors negatius per exemples oposats (a diferència de la distància euclideao Jacard). En cas de fer servir alguna d'aquestes dues, pensa (més endavant) en com afectaran els negatius en la recomanació.\n",
    "\n",
    "En la similitud cosinus, vigileu amb casos on un usuari no ha comprat res, tindreu a ser una divisió entre 0.\n",
    "\n",
    "En la correlació de Pearson, haureu de considerar casos on algun dels dos exemples tingui variància 0, ja que aleshores estareu fent una divisió entre 0. En tals casos, podeu retornar un valor per defecte o alguna de les altres mesures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def similarity(x, y):\n",
    "    \"\"\"\n",
    "    Definir quina de les similituds vols utilitzar  a l'execució.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la similitud\n",
    "    \"\"\"    \n",
    "    # Ir probando y ver cual da mejor\n",
    "    return pearson(x,y)\n",
    "\n",
    "def euclid(x, y):\n",
    "    \"\"\"\n",
    "    Retorna la distància euclidiana inversa de dos vectors n-dimensionals.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la distància euclidiana\n",
    "    \"\"\"\n",
    "    return 1/ (1 + np.sqrt(np.sum(np.power(x-y,2))))\n",
    "\n",
    "def cosine(x, y):\n",
    "    \"\"\"\n",
    "    Retorna la similitud cosinus de dos vectors n-dimensionals.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la similitud cosinus\n",
    "    \"\"\"\n",
    "    return np.dot(x,y)/np.dot(np.linalg.norm(x),np.linalg.norm(y))\n",
    "\n",
    "def pearson(x, y):\n",
    "    \"\"\"\n",
    "    Retorna la correlació de Pearson de dos vectors n-dimensionals.\n",
    "    \n",
    "    :param x: Primer vector\n",
    "    :param y: Segon vector\n",
    "    :return : Escalar (float) corresponent a la correlació de Pearson\n",
    "    \"\"\"\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    up = np.sum(np.dot((x-x_mean),(y-y_mean)))\n",
    "    down = np.dot(np.sqrt(np.sum(np.power(x-x_mean,2))), np.sqrt(np.sum(np.power(y-y_mean,2))))\n",
    "    if down == 0 : return 0\n",
    "\n",
    "    return up/down\n",
    "\n",
    "def jaccard(x, y):\n",
    "    \"\"\"\n",
    "    Similitud entre x i y segons Jaccard\n",
    "    \n",
    "    :param x: Primer vector, com a np.array\n",
    "    :param y: Segon vector, com a np.array\n",
    "    :return : Escalar (float) corresponent a la similitud\n",
    "    \"\"\"\n",
    "    # Calcular len de la union y dividir por el len de la interseccion\n",
    "    # Primero calculamos la interseccion\n",
    "    # Para ello por cada array lo pasamos a binario, con esto podemos evitar los elementos NaN y \n",
    "    # juntamos el resultado con el otro array, una vez hecho realizamos una suma para saber cuantos elementos True tenemos\n",
    "    inter = ((0 < x) & (0 < y)).sum()\n",
    "    # Despues calculamos la union, hacemos lo mismo pero con un OR\n",
    "    union = ((0 < x) | (0 < y)).sum()\n",
    "    return inter / union\n",
    "    #return np.abs(np.union1d(x,y))/np.abs(np.intersect1d(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(similarity(np.asarray([1, 1, 1]), np.asarray([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriu de similituds\n",
    "\n",
    "Per fer recomanació col·laborativa existeixen dues opcions, fer un recomanador basat en usuaris o un en ítems:\n",
    "\n",
    "* Recomanador basat en usuaris:\n",
    "Considera la matriu $M\\times N: \\text{usuaris}\\times\\text{items}$, per recomanar t'hauràs de basar en les similituds entre els usuaris.\n",
    "\n",
    "* Recomanador basat en items:\n",
    "Considera la matriu $M\\times N: \\text{items}\\times\\text{usuaris}$, per recomanar t'hauràs de basar en les similituds entre els ítems.\n",
    "\n",
    "Construeix una matriu de mida $M\\times M$ on cada posició $i,j$ indica la distància entre l'element $i$ i el $j$. Així doncs, si estàs fent un recomanador basat en usuaris, `matriu[2, 3]` contindrà la similitud entre l'usuari 2 i el 3. En canvi, si l'estàs fent basat en ítems, `matriu[2, 3]` contindrà la similitud entre l'ítem 2 i el 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Function auxiliar to get indexes, using that get the result faster\n",
    "def gen_index(array):\n",
    "    for i in range(array):\n",
    "        for j in range(i +1 ,array):\n",
    "            yield i,j\n",
    "            \n",
    "def similarity_matrix(similarity_function, df_counts):\n",
    "    \"\"\"\n",
    "    Retorna una matriu de mida M x M on cada posició \n",
    "    indica la similitud entre usuaris (resp. ítems).\n",
    "    \n",
    "    :param similarity_function: Funció que calcularà la similitud \n",
    "        entre usuaris (resp. ítems)\n",
    "    :param df_counts: Dataframe que conté el nombre de vegades que \n",
    "        un usuari ha comprat en un `aisle_id`\n",
    "    :return : Matriu numpy de mida M x M amb les similituds.\n",
    "    \"\"\"\n",
    "    size = df_counts.shape[0] # Get the size\n",
    "    main = np.zeros([size,size]) # Get the initial matrix\n",
    "    users = df_counts.to_numpy() # Get the users\n",
    "    \n",
    "    # Iterate over the generator\n",
    "    # This only will make a triangular matrix\n",
    "    for user1, user2 in tqdm(gen_index(size)):\n",
    "        main[user1,user2] = similarity_function(users[user1],users[user2])\n",
    "    \n",
    "    # Now we copy the other side of the matrix and we finished\n",
    "    main += main.T\n",
    "    return main    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per cridar aquesta funció, el primer paràmetre pot ser:\n",
    "\n",
    "* Alguna de les funcions que has programat abans (*euclid*, *cosine*, *pearson* o *jaccard*) (~@1h 30min treballant directament amb valors de numpy, ~@20h a partir de pandas pur)\n",
    "* Opcionalment (no és obligatori fer-ho) podeu programar una funció que treballi específicament amb matrius (i no vectors). Si ho feu, cal gestionar-ho quan es rep `None`. No totes les funcions anteriorment anomenades són fàcils (ni intuïtives, ni hi caben en memòria) d'aplicar en forma matricial.  (@5s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7659600c334cceba12bff7c2d4c62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    with open('similarities.pkl', 'rb') as fp:\n",
    "        similarities = pickle.load(fp)\n",
    "except:\n",
    "    similarities = similarity_matrix(similarity, df_reduced)\n",
    "    with open('similarities.pkl', 'wb') as fp:\n",
    "        pickle.dump(similarities, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generació de prediccions\n",
    "\n",
    "Per fer recomanació col·laborativa, necessitem una funció que ens doni un valor de quant bona seria la recomanació. En el nostre cas i amb les nostres dades, volem una funció que ens indiqui quants cops compraria un usuari un producte donat.\n",
    "\n",
    "* Si esteu fent un recomanador basat en usuaris, la puntuació per a un usuari $u$ i ítem $j$ és\n",
    "\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\frac{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)\\cdot r_{p,i}}{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)}$$\n",
    "\n",
    "On $r_{u,i}$ indica el nombre de vegades que l'usuari $u$ ha comprat l'l'ítem $i$.\n",
    "\n",
    "És a dir, per cada usuari $p$ diferent de $u$ si aquest usuari ha comprat algun cop el producte $i$, la similitud entre $p$ i $u$ multiplicada pel nombre de vegades que l'usuari $p$ ha comprat l'l'ítem $i$ ($r_{p,i}$).\n",
    "\n",
    "Ponderat per la suma de les similituds.\n",
    "\n",
    "* Anàlogament, si està basat en ítem, la puntuació per a un usuari $u$ i ítem $j$ és\n",
    "\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\frac{\\sum_{j\\neq i,r_{u,j}>0} sim(i, j)\\cdot r_{u,j}}{\\sum_{j\\neq i,r_{u,j}>0} sim(i, j)}$$\n",
    "\n",
    "On $r_{u,i}$ indica el nombre de vegades que l'usuari $u$ ha comprat l'ítem $j$.\n",
    "\n",
    "És a dir, per cada ítem $j$ diferent de $i$ si l'usuari al qui recomanem ha comprat l'ítem $j$, la similitud entre $i$ i $j$ multiplicada pel nombre de vegades que l'usuari al qui recomanem $u$ ha comprat l'ítem $j$ ($r_{u,j}$)\n",
    "\n",
    "Ponderat per la suma de les similituds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixeu-vos que, sigui quin sigui el cas, al final estem fent el producte vectorial entre dos vectors. Concretament, el producte vectorial entre les similituds i les compres. Fes una funció que calculi aquest resultat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(sims, counts):\n",
    "    \"\"\"\n",
    "    * Si estàs implementant basat en usuaris:\n",
    "        Donades les similituds i el nombre de vegades que l'usuari ha comprat\n",
    "        cada ítem, retorna la predicció que indica quants cops compraria \n",
    "        l'usuari un nou ítem.\n",
    "    \n",
    "        :param sims: Similituds entre usuaris\n",
    "        :param counts: Nombre de vegades que l'usuari ha comprat cada ítem,\n",
    "        :return : Predicció (float) que indica quants cops compraria l'usuari un ítem.\n",
    "        \n",
    "        \n",
    "    * Si estàs implementant basat en items:\n",
    "        Donades les similituds i el nombre de vegades que l'item a recomanar ha\n",
    "        estat comprat per cada usuari, retorna la predicció que indica quants cops\n",
    "        compraria l'usuari un nou ítem.\n",
    "    \n",
    "        :param sims: Similituds entre items\n",
    "        :param counts: Nombre de vegades que l'ítem ha estat comprat per cada usuari\n",
    "        :return : Predicció (float) que indica quants cops compraria l'usuari un ítem.\n",
    "    \"\"\"\n",
    "\n",
    "    #user based\n",
    "    #we use the dot function on the denominator becauase dot() for N-dimensional arrays,\n",
    "    #it's a sum product over the last axis of a and the second-last axis of b. Therefore,\n",
    "    #its like saying the sum of sims, and then multiply it by counts, which is the number of times a user p bought an item i\n",
    "    simPUxN = np.dot(sims, counts)\n",
    "    simPU = np.sum(sims) \n",
    "    prediction = 0\n",
    "    \n",
    "    if simPU != 0: #in case the denominator is 0\n",
    "        prediction = simPUxN / simPU\n",
    "    \n",
    "    return prediction #we dont care if the nominator is 0 becuase its going to return 0 anymays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(user, item, df, similarities):\n",
    "    \"\"\"\n",
    "    Extreu les similituds i el nombre de vegades que un usuari ha comprat un ítem\n",
    "    (resp. nombre de vegades que cada usuari ha comprat l'ítem) i crida a la funció \n",
    "    anterior per calcular les prediccions.\n",
    "    \n",
    "    :param user: ID de l'usuari per la predicció\n",
    "    :param item: ID de l'ítem per la predicció\n",
    "    :param df: Dataframe que conté el nombre de vegades que un usuari \n",
    "        ha comprat en un `aisle_id`\n",
    "    :param similarities: Matriu de similituds\n",
    "    :return : Retorna un escalar (float) amb la predicció\n",
    "    \n",
    "    \"\"\"\n",
    "    at = df.index.get_loc(user)#get the index of the user\n",
    "    return calc_score(similarities[at], df[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016404335595379505\n"
     ]
    }
   ],
   "source": [
    "print(score(df_reduced.index[0], df_reduced.columns[0], df_reduced, similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feu una funció que donat un usuari calculi per cada item que no ha comprat la puntuació d'aquest. La funció retorna els $N$ items més ben puntuats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_n_items(user_id, df, similarities, N):\n",
    "    \"\"\"\n",
    "    Donat un usuari calcula per cada ítem que no ha comprat la puntuació d'aquest. \n",
    "    La funció retorna els $N$ ítems més ben puntuats.\n",
    "    \n",
    "    :param user_id: Identificador de l'usuari\n",
    "    :parma df: Dataframe que conté el nombre de vegades que un usuari \n",
    "        ha comprat en un `aisle_id`\n",
    "    :param similarities: Matriu de similituds\n",
    "    :param N: Nombre d'ítems que volem que siguin recomanats.\n",
    "    :return : Llista amb els IDs dels ítems recomanats\n",
    "    \"\"\"    \n",
    "    users = df.loc[user_id] # Get the users\n",
    "    not_buyed = users[users == 0] # Get only the users that has buyed before\n",
    "    # Calculate the score for each user\n",
    "    res = [(score(user_id, item, df, similarities), item) for item,x in not_buyed.items()]\n",
    "    # Sort in reverse\n",
    "    res.sort(reverse = True)\n",
    "    # Get only the items\n",
    "    return [x[1] for x in res[:N]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 123, 120, 21, 84, 16, 91, 116, 112, 37]\n"
     ]
    }
   ],
   "source": [
    "print(recommend_n_items(df_reduced.index[0], df_reduced, similarities, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possibles millores \n",
    "\n",
    "Per implementar millores, dupliqueu el notebook i feu-ho en la còpia!\n",
    "\n",
    "Deixeu aquest notebook amb la implementació base.\n",
    "\n",
    "**1) Utilització completa de les dades:**\n",
    "Fer servir `df_original` tindrà (possiblement) resultats més fiables, però trigarà molt més que amb la versió reduida `df`. Pots canviar el `FRAC` a valors més alts ($\\leq 1$) per utilitzar més dades, però compte perque potser la matriu $M\\times M$ no cabrà a memòria.\n",
    "\n",
    "**2) Mesura de similitud:** \n",
    "Quina mesura de similitud heu utilitzat? És la més adient? Perquè?\n",
    "\n",
    "**3) Normalització: Prediccions escalades al domini de l'usuari:**\n",
    "Els usuaris compren en diferent mesura els productes, un més quantitat, altres menys. Fent servir la següent formula, escalem la predicció  a la mitja de l'usuari:\n",
    "$$pred(u, i) = \\hat{r}_{u,i} = \\bar{r_u} + \\frac{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)\\cdot (r_{p,i}-\\bar{r_b})}{\\sum_{p\\neq u,r_{p,i}>0} sim(u, p)}$$\n",
    "on $\\bar{r_u}$ és la mitjana de compres de l'usuari *u*.\n",
    "    \n",
    "**4) Valor del nombre d'elements codificats:**\n",
    "Redueix la similitud entre els usuaris si el nombre de productes és baix o descarta (en entrenament) aquells usuaris amb un petit nombre de productes comprats.\n",
    "\n",
    "**5) Augment de la similitud:**\n",
    "Incrementeu el pes als usuaris que són realment similars (~ = 1)\n",
    "\n",
    "**6) Selecció d'usuaris semblants:**\n",
    "Només s'utilitza un subconjunt d'usuaris similars, descartant tots aquells usuaris poc similars.\n",
    "\n",
    "**7) Són tots els usuaris/productes interessants?**\n",
    "Definir quins són aquells usuaris/productes interessants i recomanar en funció d'això.\n",
    "\n",
    "\n",
    "Totes aquestes tècniques es poden aplicar d'igual manera en la recomanació col·laborativa per usuaris o ítems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "\n",
    "Per als usuaris que tens a continuació, quins productes els hi recomanaries (**fins a un màxim de 5**) que compressin segons el que ja han comprat?\n",
    "\n",
    "https://www.kaggle.com/c/tnui2021-recommender\n",
    "\n",
    "Si feu modificacions al codi original de cara a millorar els resultats pel Kaggle, feu una còpia d'aquest notebook i treballeu-hi allà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aisle_id   1    2     3     4     5     6     7     8     9    10   ...  125  \\\n",
      "user_id                                                             ...        \n",
      "300000     0.0  0.0  14.0   0.0   0.0   0.0   0.0   8.0   0.0  0.0  ...  0.0   \n",
      "300001     0.0  0.0  24.0   0.0  24.0   0.0   0.0   0.0  24.0  0.0  ...  0.0   \n",
      "300002     0.0  0.0  10.0   0.0   0.0   0.0   0.0   0.0  15.0  0.0  ...  0.0   \n",
      "300003     0.0  0.0   7.0   0.0   0.0   0.0   0.0   0.0  19.0  0.0  ...  0.0   \n",
      "300004     0.0  0.0   0.0   0.0  14.0   0.0   0.0  27.0   0.0  0.0  ...  0.0   \n",
      "...        ...  ...   ...   ...   ...   ...   ...   ...   ...  ...  ...  ...   \n",
      "300140     0.0  0.0  24.0   0.0   0.0   0.0   0.0   0.0  24.0  0.0  ...  0.0   \n",
      "300141    16.0  0.0  20.0  20.0  16.0  14.0  16.0  20.0  20.0  0.0  ...  0.0   \n",
      "300142     0.0  0.0  15.0   0.0  15.0  18.0  15.0  18.0  18.0  0.0  ...  0.0   \n",
      "300143     0.0  0.0   0.0  20.0   0.0   0.0   0.0   0.0   0.0  0.0  ...  0.0   \n",
      "300144     0.0  0.0   0.0  20.0  12.0   0.0  14.0   0.0   0.0  0.0  ...  0.0   \n",
      "\n",
      "aisle_id  126  127   128   129   130   131   132  133  134  \n",
      "user_id                                                     \n",
      "300000    8.0  0.0   0.0   0.0  14.0   0.0   9.0  0.0  0.0  \n",
      "300001    0.0  0.0   0.0   0.0   0.0   0.0   0.0  0.0  0.0  \n",
      "300002    0.0  0.0   0.0   8.0   0.0   4.0   0.0  0.0  0.0  \n",
      "300003    0.0  7.0  19.0  19.0   0.0  19.0   0.0  0.0  0.0  \n",
      "300004    0.0  0.0   0.0  27.0   0.0   0.0  27.0  0.0  0.0  \n",
      "...       ...  ...   ...   ...   ...   ...   ...  ...  ...  \n",
      "300140    0.0  0.0  10.0   0.0  10.0  10.0   0.0  0.0  0.0  \n",
      "300141    0.0  0.0   0.0  14.0   0.0   0.0   0.0  0.0  0.0  \n",
      "300142    0.0  0.0   0.0   0.0   0.0  13.0   0.0  0.0  0.0  \n",
      "300143    0.0  0.0   0.0   7.0  20.0   7.0   0.0  0.0  0.0  \n",
      "300144    0.0  0.0  14.0   0.0   0.0  20.0   0.0  0.0  0.0  \n",
      "\n",
      "[145 rows x 134 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test_products = pd.read_csv(join('data', 'order_products__test.csv'))\n",
    "df_test_orders = pd.read_csv(join('data', 'orders__test.csv'))[['order_id', 'user_id']]\n",
    "df_test_merged = merge_information(df_test_products, df_test_orders, df_prods)\n",
    "\n",
    "df_test_counts = build_counts_table(df_test_merged)\n",
    "df_all = df_reduced.append(df_test_counts)\n",
    "df_all = df_all.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>aisle_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300141</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "aisle_id   1    2     3     4     5     6     7     8     9    10   ...  125  \\\n",
       "user_id                                                             ...        \n",
       "300140     0.0  0.0  24.0   0.0   0.0   0.0   0.0   0.0  24.0  0.0  ...  0.0   \n",
       "300141    16.0  0.0  20.0  20.0  16.0  14.0  16.0  20.0  20.0  0.0  ...  0.0   \n",
       "300142     0.0  0.0  15.0   0.0  15.0  18.0  15.0  18.0  18.0  0.0  ...  0.0   \n",
       "300143     0.0  0.0   0.0  20.0   0.0   0.0   0.0   0.0   0.0  0.0  ...  0.0   \n",
       "300144     0.0  0.0   0.0  20.0  12.0   0.0  14.0   0.0   0.0  0.0  ...  0.0   \n",
       "\n",
       "aisle_id  126  127   128   129   130   131  132  133  134  \n",
       "user_id                                                    \n",
       "300140    0.0  0.0  10.0   0.0  10.0  10.0  0.0  0.0  0.0  \n",
       "300141    0.0  0.0   0.0  14.0   0.0   0.0  0.0  0.0  0.0  \n",
       "300142    0.0  0.0   0.0   0.0   0.0  13.0  0.0  0.0  0.0  \n",
       "300143    0.0  0.0   0.0   7.0  20.0   7.0  0.0  0.0  0.0  \n",
       "300144    0.0  0.0  14.0   0.0   0.0  20.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tingueu en compte que si voleu fer un canvi a les similarities, heu d'esborrar l'arxiu similarities_test.pkl** (però l'haureu de recalcular, amb el temps que això suposi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d3e819b956435e91dd37b7eea9e39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try: \n",
    "    with open('similarities_test.pkl', 'rb') as fp:\n",
    "        similarities_test = pickle.load(fp)\n",
    "except:\n",
    "    similarities_test = similarity_matrix(similarity, df_all)\n",
    "    with open('similarities_test.pkl', 'wb') as fp:\n",
    "        pickle.dump(similarities_test, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(columns=['user_id', 'products_list'])\n",
    "\n",
    "for user_id in df_test_counts.index:\n",
    "    user_recos = recommend_n_items(user_id, df_all, similarities_test, 5)\n",
    "\n",
    "    df_submission = df_submission.append(\n",
    "        {\n",
    "            'user_id': user_id,\n",
    "            'products_list': ' '.join(map(str, user_recos))\n",
    "        }, \n",
    "        ignore_index=True)\n",
    "\n",
    "df_submission.to_csv('submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id      products_list\n",
      "0  300000    83 84 91 121 88\n",
      "1  300001   120 21 84 112 96\n",
      "2  300002   83 112 91 78 121\n",
      "3  300003  120 91 115 31 108\n",
      "4  300004    24 21 112 83 96\n"
     ]
    }
   ],
   "source": [
    "print(df_submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quan tingueu l'arxiu submission.csv generat, podeu pujar-ho a Kaggle com una submission per veure el vostre score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
